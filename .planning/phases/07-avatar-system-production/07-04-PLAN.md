---
phase: 07-avatar-system-production
plan: 04
type: execute
wave: 3
depends_on: ["07-02", "07-03"]
files_modified:
  - backend/app/services/chat.py
  - backend/app/routers/avatars.py
  - frontend/src/pages/AvatarSetupPage.tsx
  - frontend/src/api/avatars.ts
  - frontend/src/App.tsx
autonomous: true
requirements: [AVTR-01, AVTR-02, AVTR-03, AVTR-04, AVTR-05, INTM-03]

must_haves:
  truths:
    - "In intimate mode, LLM may return a send_photo tool call instead of plain text"
    - "When send_photo tool call detected, ChatService enqueues a BullMQ job and returns placeholder text to user"
    - "Placeholder text ('I'm sending you a photo...') is appended to session history â€” NOT the raw tool_calls message (Pitfall 3)"
    - "After login, if user has no avatar, they are redirected to /avatar-setup (not /chat)"
    - "AvatarSetupPage shows form with name, age, gender, nationality/race, free-text appearance, personality"
    - "After form submission, a reference image is generated and shown to the user with a Regenerate button"
    - "User approves reference image â†’ navigated to /chat (React Query cache invalidated)"
  artifacts:
    - path: "backend/app/services/chat.py"
      provides: "SEND_PHOTO_TOOL definition + intimate mode tool call detection + BullMQ enqueue"
      contains: "send_photo"
    - path: "backend/app/routers/avatars.py"
      provides: "POST /avatars/me/reference-image endpoint for onboarding reference image generation"
      contains: "reference-image"
    - path: "frontend/src/pages/AvatarSetupPage.tsx"
      provides: "Onboarding form + reference image preview + regenerate loop"
      min_lines: 80
    - path: "frontend/src/api/avatars.ts"
      provides: "createAvatar(), generateReferenceImage(), getMyAvatar()"
      exports: ["createAvatar", "generateReferenceImage", "getMyAvatar"]
    - path: "frontend/src/App.tsx"
      provides: "Onboarding gate: redirect to /avatar-setup when no avatar; /avatar-setup and /subscribe routes"
      contains: "avatar-setup"
  key_links:
    - from: "backend/app/services/chat.py"
      to: "backend/app/services/jobs/queue.py"
      via: "enqueue_photo_job() called when finish_reason == 'tool_calls' in intimate mode"
      pattern: "enqueue_photo_job"
    - from: "frontend/src/pages/AvatarSetupPage.tsx"
      to: "frontend/src/api/avatars.ts"
      via: "createAvatar() on form submit, generateReferenceImage() for preview"
      pattern: "createAvatar|generateReferenceImage"
    - from: "frontend/src/App.tsx"
      to: "GET /avatars/me"
      via: "useQuery for avatar existence check, redirect to /avatar-setup if 404"
      pattern: "avatar-setup"
---

<objective>
Wire the LLM send_photo tool call into ChatService, and build the avatar onboarding flow (AvatarSetupPage with reference image preview).

Purpose: These two pieces complete the intimate mode photo loop (INTM-03) on the backend and the avatar setup UX (AVTR-01 through AVTR-05) on the frontend. Both depend on Plan 02 (avatar model/billing) and Plan 03 (worker queue).

Output: ChatService extended with send_photo tool call detection + enqueue; AvatarSetupPage with form + reference image generation loop; App.tsx onboarding gate.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-avatar-system-production/07-CONTEXT.md
@.planning/phases/07-avatar-system-production/07-RESEARCH.md
@backend/app/services/chat.py
@backend/app/services/llm/openai_provider.py
@backend/app/routers/avatars.py
@frontend/src/App.tsx
@frontend/src/api/preferences.ts
@frontend/src/store/useAuthStore.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: ChatService send_photo tool call + BullMQ enqueue in intimate mode</name>
  <files>backend/app/services/chat.py</files>
  <action>
Extend `backend/app/services/chat.py` to detect the LLM's send_photo tool call in intimate mode and enqueue a BullMQ photo job.

**IMPORTANT â€” Read chat.py before writing anything.**

After reading the file you will confirm these two attributes already exist in `ChatService.__init__` and must NOT be added again:

```python
# Already in __init__ (line ~101-102) â€” DO NOT redeclare:
self._openai_client = AsyncOpenAI(api_key=_settings.openai_api_key, max_retries=1)
self._intent_model = _settings.llm_model
```

`self._openai_client` is a raw `AsyncOpenAI` instance â€” it already exposes `.chat.completions.create()`.
`self._intent_model` is a string â€” accessible anywhere on `self` inside `handle_message()`.
Neither attribute needs to be added. The plan's code uses them as-is.

**Changes to make (surgical â€” do not rewrite the entire file):**

1. Add `import json` at the top of the file (after the existing imports) â€” needed to parse tool call arguments. Skip this if `import json` is already present.

2. Add SEND_PHOTO_TOOL definition near the top of the file (after the existing constants, before the class definition):

```python
# Tool definition for intimate mode LLM calls (INTM-03)
# LLM calls this when it decides the moment is right for a photo
SEND_PHOTO_TOOL = {
    "type": "function",
    "function": {
        "name": "send_photo",
        "description": (
            "Send an AI-generated photo of yourself to the user. "
            "Use when the user asks for a photo, or when you decide the moment is right. "
            "Describe the scene, pose, setting, and mood in detail."
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "scene_description": {
                    "type": "string",
                    "description": (
                        "Detailed description of the photo: "
                        "setting, lighting, pose, mood, what you are wearing or doing."
                    ),
                },
            },
            "required": ["scene_description"],
        },
    },
}

PHOTO_PLACEHOLDER_MSG = "I'm sending you a photo... give me a moment ðŸ“¸"
```

3. In `handle_message()`, locate the existing LLM call block:

```python
        try:
            reply = await self._llm.complete(history + [user_message], system_prompt)
        except Exception as e:
            logger.error(f"LLM call failed for user {user_id}: {e}")
            reply = LLM_ERROR_MSG
```

Replace this entire `try/except` block with the new intimate-mode-aware version below. In SECRETARY mode the behaviour is identical to before (calls `self._llm.complete()`). In INTIMATE mode it calls `self._openai_client.chat.completions.create()` directly with `tools=[SEND_PHOTO_TOOL]`, then inspects `finish_reason` to decide whether to enqueue a photo job or return normal text.

```python
        try:
            if current_mode == ConversationMode.INTIMATE:
                # Intimate mode: include send_photo tool â€” LLM decides when to send a photo
                full_messages = [{"role": "system", "content": system_prompt}] + history + [user_message]
                response = await self._openai_client.chat.completions.create(
                    model=self._intent_model,
                    messages=full_messages,
                    tools=[SEND_PHOTO_TOOL],
                    tool_choice="auto",
                )
                choice = response.choices[0]
                if choice.finish_reason == "tool_calls" and choice.message.tool_calls:
                    # LLM wants to send a photo
                    tool_call = choice.message.tool_calls[0]
                    if tool_call.function.name == "send_photo":
                        args = json.loads(tool_call.function.arguments)
                        scene_description = args.get("scene_description", "a beautiful photo")
                        # Enqueue BullMQ job (non-blocking â€” do not await delivery)
                        from app.services.jobs.queue import enqueue_photo_job
                        channel = "web"  # default; webhook.py may override for WhatsApp
                        await enqueue_photo_job(
                            user_id=user_id,
                            scene_description=scene_description,
                            avatar=avatar,
                            channel=channel,
                        )
                        reply = PHOTO_PLACEHOLDER_MSG
                        # CRITICAL: append placeholder text (NOT the tool_calls message)
                        # to history â€” prevents OpenAI "tool message must follow tool_calls" error
                        # (RESEARCH.md Pitfall 3)
                    else:
                        reply = choice.message.content or LLM_ERROR_MSG
                else:
                    reply = choice.message.content or LLM_ERROR_MSG
            else:
                # Secretary mode: standard LLM call (no tools)
                reply = await self._llm.complete(history + [user_message], system_prompt)
        except Exception as e:
            logger.error(f"LLM call failed for user {user_id}: {e}")
            reply = LLM_ERROR_MSG
```

Note: The channel in ChatService is set to "web" as default. The webhook.py router (WhatsApp) should pass the channel when calling enqueue_photo_job. For the initial implementation, detecting channel inside ChatService is acceptable â€” the avatar dict and session don't carry channel info. A follow-on improvement (post-beta) can add channel to handle_message() signature. For now, web is the primary delivery channel per CONTEXT.md (web app phase).

No other changes to chat.py. Preserve all existing gates (crisis, content guard, mode switching, skill dispatch).
  </action>
  <verify>
    <automated>cd "C:/Users/raphg/Desktop/IA/ava2/backend" && python -c "from app.services.chat import ChatService, SEND_PHOTO_TOOL, PHOTO_PLACEHOLDER_MSG; print('SEND_PHOTO_TOOL name:', SEND_PHOTO_TOOL['function']['name']); print('Placeholder:', PHOTO_PLACEHOLDER_MSG[:30]); print('ChatService imports OK')"</automated>
    <manual>Run existing test suite: `cd backend && python -m pytest tests/ -x -q 2>&1 | tail -5` â€” all existing tests must still pass (tool call addition is additive, not breaking).</manual>
    <sampling_rate>run after task 1</sampling_rate>
  </verify>
  <done>
    SEND_PHOTO_TOOL defined in chat.py. Intimate mode LLM call uses tools=[SEND_PHOTO_TOOL] via self._openai_client (already in __init__). When finish_reason == "tool_calls" with send_photo, enqueue_photo_job() is called and PHOTO_PLACEHOLDER_MSG returned. Placeholder text (not raw tool_calls message) appended to session history. Secretary mode unchanged. Existing tests still pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: AvatarSetupPage + avatars API module + App.tsx onboarding gate + POST /avatars/me/reference-image endpoint</name>
  <files>
    frontend/src/pages/AvatarSetupPage.tsx
    frontend/src/api/avatars.ts
    frontend/src/App.tsx
    backend/app/routers/avatars.py
  </files>
  <action>
**`frontend/src/api/avatars.ts`** â€” Avatar API client module.

IMPORTANT: Do NOT include an `updateAvatar` function. Avatar is locked once created during onboarding â€” it cannot be modified afterward (user decision). Only these functions are needed:
- `getMyAvatar`: GET /avatars/me â€” used by App.tsx onboarding gate
- `createAvatar`: POST /avatars â€” called on first setup during onboarding
- `generateReferenceImage`: POST /avatars/me/reference-image â€” triggers reference image generation

```typescript
/**
 * Avatar API client module.
 * createAvatar: POST /avatars â€” called on first (and only) setup during onboarding
 * generateReferenceImage: POST /avatars/me/reference-image â€” triggers reference image generation
 * getMyAvatar: GET /avatars/me â€” used by App.tsx onboarding gate
 *
 * NOTE: No updateAvatar â€” avatar is locked after onboarding (user decision).
 */

export interface AvatarData {
  name: string
  age: number
  personality: string
  physical_description?: string
  gender?: string
  nationality?: string
}

export interface AvatarResponse extends AvatarData {
  id: string
  user_id: string
  created_at: string
  reference_image_url?: string
}

export async function getMyAvatar(token: string): Promise<AvatarResponse | null> {
  const res = await fetch('/avatars/me', {
    headers: { Authorization: `Bearer ${token}` },
  })
  if (res.status === 404) return null
  if (!res.ok) throw new Error('Failed to fetch avatar')
  return res.json()
}

export async function createAvatar(token: string, data: AvatarData): Promise<AvatarResponse> {
  const res = await fetch('/avatars', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${token}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(data),
  })
  if (!res.ok) {
    const err = await res.json().catch(() => ({ detail: 'Unknown error' }))
    throw new Error(err.detail || 'Failed to create avatar')
  }
  return res.json()
}

export async function generateReferenceImage(token: string): Promise<{ reference_image_url: string }> {
  const res = await fetch('/avatars/me/reference-image', {
    method: 'POST',
    headers: { Authorization: `Bearer ${token}` },
  })
  if (!res.ok) {
    const err = await res.json().catch(() => ({ detail: 'Image generation failed' }))
    throw new Error(err.detail || 'Image generation failed')
  }
  return res.json()
}
```

**`frontend/src/pages/AvatarSetupPage.tsx`** â€” Onboarding form + reference image preview loop.

This page is shown once during onboarding only. Avatar cannot be edited after creation.

```tsx
/**
 * AvatarSetupPage â€” shown once during onboarding (before /chat access).
 * Avatar is locked after this step â€” it cannot be modified post-signup.
 *
 * Flow per CONTEXT.md locked decision:
 *   1. User fills in avatar details (all four AVTR-01 through AVTR-04 fields)
 *   2. Submit â†’ createAvatar â†’ generateReferenceImage
 *   3. Show reference image with Regenerate button
 *   4. User approves â†’ navigate to /chat (avatar query invalidated)
 */
import { useState } from 'react'
import { useNavigate } from 'react-router-dom'
import { useQueryClient } from '@tanstack/react-query'
import { useAuthStore } from '../store/useAuthStore'
import { createAvatar, generateReferenceImage, type AvatarData } from '../api/avatars'

const PERSONALITIES = [
  { value: 'playful', label: 'Playful' },
  { value: 'dominant', label: 'Dominant' },
  { value: 'shy', label: 'Shy' },
  { value: 'caring', label: 'Caring' },
  { value: 'intellectual', label: 'Intellectual' },
  { value: 'adventurous', label: 'Adventurous' },
]

export default function AvatarSetupPage() {
  const token = useAuthStore(s => s.token)!
  const navigate = useNavigate()
  const queryClient = useQueryClient()

  const [form, setForm] = useState<AvatarData>({
    name: '',
    age: 25,
    personality: 'caring',
    gender: '',
    nationality: '',
    physical_description: '',
  })
  const [saving, setSaving] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [referenceImageUrl, setReferenceImageUrl] = useState<string | null>(null)
  const [generating, setGenerating] = useState(false)

  const handleChange = (field: keyof AvatarData, value: string | number) => {
    setForm(prev => ({ ...prev, [field]: value }))
  }

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault()
    setError(null)
    setSaving(true)
    try {
      // Create avatar (one-time â€” locked after this step)
      await createAvatar(token, form)
      // Generate reference image immediately (locked decision from CONTEXT.md)
      await handleGenerateReference()
    } catch (err: unknown) {
      setError(err instanceof Error ? err.message : 'Something went wrong')
    } finally {
      setSaving(false)
    }
  }

  const handleGenerateReference = async () => {
    setGenerating(true)
    setError(null)
    try {
      const result = await generateReferenceImage(token)
      setReferenceImageUrl(result.reference_image_url)
    } catch (err: unknown) {
      setError(err instanceof Error ? err.message : 'Image generation failed')
    } finally {
      setGenerating(false)
    }
  }

  const handleApprove = async () => {
    // Invalidate avatar query so App.tsx gate sees the new avatar and routes to /chat
    // (RESEARCH.md Pitfall 7: cache invalidation prevents redirect loop)
    await queryClient.invalidateQueries({ queryKey: ['avatar'] })
    navigate('/chat', { replace: true })
  }

  return (
    <div className="min-h-screen bg-gray-950 text-white flex items-center justify-center p-4">
      <div className="w-full max-w-lg bg-gray-900 rounded-2xl p-8 space-y-6">
        <div>
          <h1 className="text-2xl font-bold">Meet your Ava</h1>
          <p className="text-gray-400 mt-1 text-sm">
            Describe your companion â€” we'll generate her look and you can adjust until it's perfect.
          </p>
        </div>

        {!referenceImageUrl ? (
          <form onSubmit={handleSubmit} className="space-y-4">
            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">Name</label>
              <input
                type="text"
                required
                value={form.name}
                onChange={e => handleChange('name', e.target.value)}
                placeholder="e.g. Ava"
                className="w-full bg-gray-800 border border-gray-700 rounded-lg px-3 py-2 text-white placeholder-gray-500 focus:outline-none focus:border-purple-500"
              />
            </div>

            <div className="grid grid-cols-2 gap-4">
              <div>
                <label className="block text-sm font-medium text-gray-300 mb-1">Age (20+)</label>
                <input
                  type="number"
                  required
                  min={20}
                  max={99}
                  value={form.age}
                  onChange={e => handleChange('age', parseInt(e.target.value, 10))}
                  className="w-full bg-gray-800 border border-gray-700 rounded-lg px-3 py-2 text-white focus:outline-none focus:border-purple-500"
                />
              </div>
              <div>
                <label className="block text-sm font-medium text-gray-300 mb-1">Gender</label>
                <input
                  type="text"
                  value={form.gender || ''}
                  onChange={e => handleChange('gender', e.target.value)}
                  placeholder="e.g. woman"
                  className="w-full bg-gray-800 border border-gray-700 rounded-lg px-3 py-2 text-white placeholder-gray-500 focus:outline-none focus:border-purple-500"
                />
              </div>
            </div>

            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">Nationality / Ethnicity</label>
              <input
                type="text"
                value={form.nationality || ''}
                onChange={e => handleChange('nationality', e.target.value)}
                placeholder="e.g. French, Japanese, Brazilian..."
                className="w-full bg-gray-800 border border-gray-700 rounded-lg px-3 py-2 text-white placeholder-gray-500 focus:outline-none focus:border-purple-500"
              />
            </div>

            <div>
              <label className="block text-sm font-medium text-gray-300 mb-1">Appearance</label>
              <textarea
                value={form.physical_description || ''}
                onChange={e => handleChange('physical_description', e.target.value)}
                placeholder="e.g. dark wavy hair, brown eyes, athletic build, casual style..."
                rows={3}
                className="w-full bg-gray-800 border border-gray-700 rounded-lg px-3 py-2 text-white placeholder-gray-500 focus:outline-none focus:border-purple-500 resize-none"
              />
            </div>

            <div>
              <label className="block text-sm font-medium text-gray-300 mb-2">Personality</label>
              <div className="grid grid-cols-3 gap-2">
                {PERSONALITIES.map(p => (
                  <button
                    key={p.value}
                    type="button"
                    onClick={() => handleChange('personality', p.value)}
                    className={`py-2 px-3 rounded-lg text-sm font-medium transition-colors ${
                      form.personality === p.value
                        ? 'bg-purple-600 text-white'
                        : 'bg-gray-800 text-gray-300 hover:bg-gray-700'
                    }`}
                  >
                    {p.label}
                  </button>
                ))}
              </div>
            </div>

            {error && (
              <p className="text-red-400 text-sm">{error}</p>
            )}

            <button
              type="submit"
              disabled={saving || !form.name}
              className="w-full bg-purple-600 hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed text-white font-semibold py-3 rounded-xl transition-colors"
            >
              {saving ? 'Creating your Ava...' : 'Create Ava & Generate Photo'}
            </button>
          </form>
        ) : (
          /* Reference image preview + approve/regenerate loop */
          <div className="space-y-4">
            <p className="text-sm text-gray-400">
              Here's your Ava â€” approve this look or regenerate until you're happy.
            </p>
            <img
              src={referenceImageUrl}
              alt="Your Ava reference"
              className="w-full rounded-xl object-cover aspect-[2/3]"
            />
            {error && <p className="text-red-400 text-sm">{error}</p>}
            <div className="flex gap-3">
              <button
                onClick={handleGenerateReference}
                disabled={generating}
                className="flex-1 bg-gray-700 hover:bg-gray-600 disabled:opacity-50 text-white font-medium py-3 rounded-xl transition-colors"
              >
                {generating ? 'Generating...' : 'Regenerate'}
              </button>
              <button
                onClick={handleApprove}
                className="flex-1 bg-purple-600 hover:bg-purple-700 text-white font-semibold py-3 rounded-xl transition-colors"
              >
                Looks perfect
              </button>
            </div>
          </div>
        )}
      </div>
    </div>
  )
}
```

**`frontend/src/App.tsx`** â€” Add onboarding gate and new routes.

Key changes:
1. Add `AvatarSetupPage` and `SubscribePage` imports
2. Add `useQuery` for avatar existence check inside a new `OnboardingGate` component
3. Add routes `/avatar-setup` and `/subscribe`
4. `ProtectedRoute` now includes onboarding gate: if no avatar â†’ redirect to `/avatar-setup`

```tsx
import { BrowserRouter, Routes, Route, Navigate } from 'react-router-dom'
import { QueryClient, QueryClientProvider, useQuery } from '@tanstack/react-query'
import { useAuthStore } from './store/useAuthStore'
import LoginPage from './pages/LoginPage'
import ChatPage from './pages/ChatPage'
import SettingsPage from './pages/SettingsPage'
import PhotoPage from './pages/PhotoPage'
import AvatarSetupPage from './pages/AvatarSetupPage'
import SubscribePage from './pages/SubscribePage'
import { getMyAvatar } from './api/avatars'

const queryClient = new QueryClient()

function ProtectedRoute({ children }: { children: React.ReactNode }) {
  const token = useAuthStore(s => s.token)
  if (!token) return <Navigate to="/login" replace />
  return <>{children}</>
}

/**
 * OnboardingGate â€” wraps /chat and /settings.
 * Redirects to /avatar-setup if user has not yet created an avatar.
 * Uses React Query with queryKey ['avatar'] so AvatarSetupPage can invalidate it on completion.
 */
function OnboardingGate({ children }: { children: React.ReactNode }) {
  const token = useAuthStore(s => s.token)!
  const { data: avatar, isLoading } = useQuery({
    queryKey: ['avatar'],
    queryFn: () => getMyAvatar(token),
    staleTime: 5 * 60 * 1000, // 5 min cache â€” re-checks on window focus
    retry: false,
  })

  if (isLoading) {
    return (
      <div className="min-h-screen bg-gray-950 flex items-center justify-center">
        <p className="text-gray-400">Loading...</p>
      </div>
    )
  }

  // No avatar found (404 returns null from getMyAvatar) â†’ send to onboarding
  if (avatar === null) return <Navigate to="/avatar-setup" replace />

  return <>{children}</>
}

export default function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <BrowserRouter>
        <Routes>
          <Route path="/login" element={<LoginPage />} />
          <Route
            path="/avatar-setup"
            element={<ProtectedRoute><AvatarSetupPage /></ProtectedRoute>}
          />
          <Route
            path="/subscribe"
            element={<ProtectedRoute><SubscribePage /></ProtectedRoute>}
          />
          <Route
            path="/chat"
            element={
              <ProtectedRoute>
                <OnboardingGate>
                  <ChatPage />
                </OnboardingGate>
              </ProtectedRoute>
            }
          />
          <Route
            path="/settings"
            element={
              <ProtectedRoute>
                <OnboardingGate>
                  <SettingsPage />
                </OnboardingGate>
              </ProtectedRoute>
            }
          />
          <Route path="/photo" element={<PhotoPage />} />
          <Route path="*" element={<Navigate to="/chat" replace />} />
        </Routes>
      </BrowserRouter>
    </QueryClientProvider>
  )
}
```

Note: `SubscribePage` is imported here but created in Plan 05. Create a minimal stub at `frontend/src/pages/SubscribePage.tsx` to prevent TypeScript errors during this plan's build:
```tsx
export default function SubscribePage() {
  return <div className="min-h-screen bg-gray-950 text-white flex items-center justify-center"><p>Subscribe â€” coming soon</p></div>
}
```

**`backend/app/routers/avatars.py`** â€” Add `POST /avatars/me/reference-image` endpoint. This endpoint calls the ImageProvider to generate a reference image immediately and returns the signed URL. Add after the existing `update_persona` endpoint:

```python
@router.post("/me/reference-image")
async def generate_reference_image(
    user=Depends(get_current_user),
    db=Depends(get_authed_supabase),
):
    """
    Generate a reference image for the user's avatar using the ImageProvider.
    Returns a 24-hour signed URL for the generated image.
    Called by AvatarSetupPage after form submission.
    """
    from app.services.image.replicate_provider import ReplicateProvider
    from app.services.image.prompt_builder import build_avatar_prompt
    from app.services.image.watermark import apply_watermark
    from app.database import supabase_admin
    import httpx
    import uuid

    avatar_result = db.from_("avatars").select("*").eq("user_id", str(user.id)).execute()
    if not avatar_result.data:
        raise HTTPException(status_code=404, detail="No avatar found â€” create avatar first")
    avatar = avatar_result.data[0]

    try:
        provider = ReplicateProvider()
        prompt = build_avatar_prompt(avatar, "portrait photo, neutral background, natural light, full face")
        generated = await provider.generate(prompt, aspect_ratio="2:3")

        async with httpx.AsyncClient(timeout=60.0) as client:
            resp = await client.get(generated.url)
            resp.raise_for_status()
            image_bytes = resp.content

        watermarked = apply_watermark(image_bytes)
        job_id = str(uuid.uuid4())
        storage_path = f"{str(user.id)}/reference_{job_id}.jpg"

        supabase_admin.storage.from_("photos").upload(
            storage_path,
            watermarked,
            file_options={"content-type": "image/jpeg", "upsert": "true"},
        )

        sign_response = (
            supabase_admin.storage
            .from_("photos")
            .create_signed_url(storage_path, 86400)
        )
        signed_url = sign_response.get("signedURL") or sign_response.get("signed_url")
        if not signed_url:
            raise HTTPException(status_code=500, detail="Failed to generate signed URL")

        return {"reference_image_url": signed_url}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Reference image generation failed for user {str(user.id)}: {e}")
        raise HTTPException(status_code=500, detail="Image generation failed")
```
  </action>
  <verify>
    <automated>cd "C:/Users/raphg/Desktop/IA/ava2/frontend" && npm run build 2>&1 | tail -10</automated>
    <manual>Verify: `python -c "from app.services.chat import SEND_PHOTO_TOOL, PHOTO_PLACEHOLDER_MSG; print('OK')"` passes. Frontend build shows zero TypeScript errors. Confirm no `updateAvatar` reference exists in avatars.ts or AvatarSetupPage.tsx.</manual>
    <sampling_rate>run after task 2</sampling_rate>
  </verify>
  <done>
    SEND_PHOTO_TOOL in chat.py. Intimate mode LLM call detects tool_calls response and calls enqueue_photo_job(). Placeholder text appended to history (not raw tool_calls). AvatarSetupPage.tsx form with all 4 AVTR fields + reference image preview + regenerate loop. avatars.ts module with createAvatar/generateReferenceImage/getMyAvatar only (no updateAvatar â€” avatar locked post-onboarding). App.tsx OnboardingGate redirects to /avatar-setup when avatar is null. SubscribePage stub prevents TypeScript errors. POST /avatars/me/reference-image endpoint added to avatars.py router. Frontend build passes.
  </done>
</task>

</tasks>

<verification>
- `cd backend && python -c "from app.services.chat import SEND_PHOTO_TOOL; print(SEND_PHOTO_TOOL['function']['name'])"` â†’ "send_photo"
- `cd backend && python -m pytest tests/ -x -q 2>&1 | tail -3` â€” all existing tests pass
- `cd frontend && npm run build 2>&1 | tail -5` â€” zero TypeScript errors
- `grep "avatar-setup" frontend/src/App.tsx` â€” route present
- `grep "OnboardingGate" frontend/src/App.tsx` â€” gate applied to /chat and /settings
- `grep "enqueue_photo_job" backend/app/services/chat.py` â€” wired in intimate mode
- `grep "reference-image" backend/app/routers/avatars.py` â€” endpoint present
- `grep -c "updateAvatar" frontend/src/api/avatars.ts` â†’ 0 (function not present)
- `grep -c "updateAvatar" frontend/src/pages/AvatarSetupPage.tsx` â†’ 0 (not imported or called)
</verification>

<success_criteria>
1. send_photo tool call detection: intimate mode LLM with tools=[SEND_PHOTO_TOOL]; finish_reason "tool_calls" triggers enqueue_photo_job()
2. Placeholder message returned to user (not raw tool_calls); appended to session history safely
3. AvatarSetupPage: form with name, age (20+ enforced), gender, nationality/race, appearance, personality
4. Reference image generated immediately after form submit via POST /avatars/me/reference-image
5. Regenerate loop: user can regenerate until satisfied
6. Approve: queryClient.invalidateQueries(['avatar']) + navigate to /chat
7. App.tsx OnboardingGate: redirects to /avatar-setup when GET /avatars/me returns 404
8. POST /avatars/me/reference-image endpoint added to avatars router (generates, watermarks, uploads, returns signed URL)
9. Frontend builds with zero TypeScript errors
10. No updateAvatar function in avatars.ts â€” avatar is locked after onboarding (user decision)
</success_criteria>

<output>
After completion, create `.planning/phases/07-avatar-system-production/07-04-SUMMARY.md`
</output>
