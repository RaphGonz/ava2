---
phase: 07-avatar-system-production
plan: 03
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - backend/app/services/jobs/__init__.py
  - backend/app/services/jobs/queue.py
  - backend/app/services/jobs/processor.py
  - backend/worker_main.py
  - backend/requirements.txt
autonomous: true
requirements: [INTM-03, ARCH-03]

must_haves:
  truths:
    - "A photo job can be enqueued to the BullMQ queue without error"
    - "Worker processor downloads image from Replicate URL, applies watermark, uploads to Supabase Storage, delivers signed URL to user"
    - "Web delivery: photo stored as assistant message in messages table (channel='web') so GET /chat/history returns it"
    - "WhatsApp delivery: signed URL sent via send_whatsapp_message() to user's phone"
    - "Failed jobs retry 3 times with exponential backoff before dead-letter"
    - "After all retries exhausted, user receives a failure notification"
    - "worker_main.py is a standalone entry point (python worker_main.py) for Docker"
    - "Uploaded photos stored in Supabase Storage under path: {user_id}/{job_id}.jpg"
  artifacts:
    - path: "backend/app/services/jobs/queue.py"
      provides: "get_photo_queue() singleton + enqueue_photo_job()"
      exports: ["get_photo_queue", "enqueue_photo_job"]
    - path: "backend/app/services/jobs/processor.py"
      provides: "process_photo_job() — full pipeline: download → watermark → upload → deliver"
      exports: ["process_photo_job"]
    - path: "backend/worker_main.py"
      provides: "BullMQ Worker entry point with concurrency=3 and Redis connection"
      contains: "Worker"
  key_links:
    - from: "backend/app/services/jobs/processor.py"
      to: "backend/app/services/image/watermark.py"
      via: "apply_watermark() called on downloaded bytes"
      pattern: "apply_watermark"
    - from: "backend/app/services/jobs/processor.py"
      to: "backend/app/services/image/replicate_provider.py"
      via: "ReplicateProvider().generate() called with built prompt"
      pattern: "ReplicateProvider"
    - from: "backend/app/services/jobs/processor.py"
      to: "backend/app/services/image/prompt_builder.py"
      via: "build_avatar_prompt(avatar, scene_description) before Replicate call"
      pattern: "build_avatar_prompt"
    - from: "backend/app/services/jobs/processor.py"
      to: "supabase_admin.storage"
      via: "upload watermarked JPEG to photos bucket under {user_id}/{job_id}.jpg"
      pattern: "storage\\.from_.*upload"
    - from: "backend/app/services/jobs/processor.py"
      to: "supabase_admin.messages table"
      via: "insert assistant photo message for web delivery (channel='web')"
      pattern: "messages.*insert"
    - from: "backend/app/services/jobs/processor.py"
      to: "backend/app/services/whatsapp.py"
      via: "send_whatsapp_message() for WhatsApp delivery"
      pattern: "send_whatsapp_message"
---

<objective>
Build the complete BullMQ photo generation worker pipeline — from job enqueue through Replicate image generation, Pillow watermarking, Supabase Storage upload, and final delivery to the user.

Purpose: This is the core of INTM-03. Without this worker, the send_photo LLM tool call (added in Plan 04) has no backend to process it. The worker is a separate Docker service — it never blocks the FastAPI request handler.

Output: Queue singleton, job processor (full 8-step pipeline), worker entry point (python worker_main.py).
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-avatar-system-production/07-CONTEXT.md
@.planning/phases/07-avatar-system-production/07-RESEARCH.md
@backend/app/services/image/base.py
@backend/app/services/image/replicate_provider.py
@backend/app/services/image/prompt_builder.py
@backend/app/services/image/watermark.py
@backend/app/routers/web_chat.py
@backend/app/adapters/whatsapp_adapter.py
@backend/app/services/whatsapp.py
@backend/app/routers/photo.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: BullMQ queue singleton + photo job processor (full pipeline)</name>
  <files>
    backend/app/services/jobs/__init__.py
    backend/app/services/jobs/queue.py
    backend/app/services/jobs/processor.py
    backend/requirements.txt
  </files>
  <action>
Create `backend/app/services/jobs/` package.

**`backend/app/services/jobs/__init__.py`** — empty

**`backend/app/services/jobs/queue.py`** — Queue singleton + enqueue helper:
```python
"""
BullMQ photo generation queue (enqueue side only — no Worker import here).

Only the FastAPI web process uses this module to add jobs.
The worker process (worker_main.py) uses BullMQ Worker directly.

Anti-pattern avoided: importing BullMQ Worker in the web process (RESEARCH.md anti-patterns).
"""
import logging
from urllib.parse import urlparse
from bullmq import Queue
from app.config import settings

logger = logging.getLogger(__name__)

_photo_queue: Queue | None = None


def get_photo_queue() -> Queue:
    """Return module-level Queue singleton. Lazy init on first call."""
    global _photo_queue
    if _photo_queue is None:
        host = "redis"
        port = 6379
        if settings.redis_url:
            try:
                parsed = urlparse(settings.redis_url)
                host = parsed.hostname or host
                port = parsed.port or port
            except Exception:
                pass
        _photo_queue = Queue(
            "photo_generation",
            {"connection": {"host": host, "port": port}},
        )
    return _photo_queue


async def enqueue_photo_job(
    user_id: str,
    scene_description: str,
    avatar: dict,
    channel: str,
) -> None:
    """
    Enqueue a photo generation job to BullMQ.

    Args:
        user_id: Authenticated user's UUID.
        scene_description: Scene/pose description from LLM send_photo tool call.
        avatar: Full avatar dict (must include gender, nationality, physical_description).
        channel: "web" or "whatsapp" (for delivery routing in processor).
    """
    queue = get_photo_queue()
    await queue.add(
        "generate_photo",
        {
            "user_id": user_id,
            "scene_description": scene_description,
            "avatar": avatar,
            "channel": channel,
        },
        {
            "attempts": 3,
            "backoff": {"type": "exponential", "delay": 2000},  # 2s, 4s, 8s retries
            "removeOnComplete": 100,
            "removeOnFail": 200,
        },
    )
    logger.info(f"Photo job enqueued for user {user_id}, channel={channel}")
```

**`backend/app/services/jobs/processor.py`** — Full pipeline processor. Delivery strategy:
- Web: Insert an `assistant` message row directly into `messages` table (channel='web'). GET /chat/history will return it on next poll. Frontend renders `[PHOTO]url[/PHOTO]` markers as inline images.
- WhatsApp: Call `send_whatsapp_message()` directly using user's stored phone number (same pattern as WhatsAppAdapter.send()).

```python
"""
BullMQ photo job processor — called by the Worker for each 'generate_photo' job.

Delivery strategy:
  - Web: Insert assistant photo message into messages table. Frontend polls /chat/history.
  - WhatsApp: Send signed URL link via Meta WhatsApp API (PLAT-03 — no inline NSFW).

Full pipeline per job:
  1. Build FLUX prompt from avatar fields + scene description
  2. Call Replicate FLUX API -> temporary CDN URL
  3. Download image bytes via httpx (download immediately — URL expires ~1h)
  4. Apply Pillow watermark (compliance requirement per CONTEXT.md)
  5. Upload watermarked JPEG to Supabase Storage: photos/{user_id}/{job_id}.jpg
  6. Generate 24-hour Supabase signed URL
  7. Audit log (compliance)
  8. Deliver to user via channel-appropriate method
  9. On all-retries-exhausted: notify user of failure
"""
import logging
import httpx
from app.services.image.replicate_provider import ReplicateProvider
from app.services.image.prompt_builder import build_avatar_prompt
from app.services.image.watermark import apply_watermark
from app.database import supabase_admin

logger = logging.getLogger(__name__)

PHOTO_BUCKET = "photos"
SIGNED_URL_EXPIRY = 86400  # 24 hours

_image_provider = ReplicateProvider()

PHOTO_FAILURE_MSG = (
    "I wasn't able to send you a photo right now — please try again later."
)


async def _deliver_web(user_id: str, avatar: dict, signed_url: str) -> None:
    """Store photo as assistant message in messages table. Frontend polls /chat/history."""
    # [PHOTO]url[/PHOTO] is a frontend render hint — ChatBubble renders it as <img>
    content = f"[PHOTO]{signed_url}[/PHOTO]"
    avatar_id = avatar.get("id") if avatar else None
    supabase_admin.from_("messages").insert({
        "user_id": user_id,
        "avatar_id": avatar_id,
        "channel": "web",
        "role": "assistant",
        "content": content,
    }).execute()


async def _deliver_whatsapp(user_id: str, signed_url: str) -> None:
    """Send signed URL link via WhatsApp (PLAT-03 — no inline NSFW images on WhatsApp)."""
    from app.services.whatsapp import send_whatsapp_message
    from app.config import settings

    result = (
        supabase_admin
        .from_("user_preferences")
        .select("whatsapp_phone")
        .eq("user_id", user_id)
        .maybe_single()
        .execute()
    )
    phone = (result.data or {}).get("whatsapp_phone")
    if not phone:
        logger.warning(f"No WhatsApp phone for user {user_id} — cannot deliver photo")
        return

    message = f"Here's your photo (link valid 24h): {signed_url}"
    await send_whatsapp_message(
        phone_number_id=settings.whatsapp_phone_number_id,
        to=phone,
        text=message,
    )


async def process_photo_job(job, token: str | None = None) -> None:
    """
    BullMQ Worker processor function.
    Receives job.data: {user_id, scene_description, avatar, channel}.

    On success: delivers photo to user via channel.
    On final failure: sends user a failure notification.
    BullMQ handles retries automatically per attempts/backoff config in queue.py.
    """
    data = job.data
    user_id: str = data["user_id"]
    scene_description: str = data["scene_description"]
    avatar: dict = data["avatar"]
    channel: str = data.get("channel", "web")
    job_id: str = str(job.id)

    logger.info(f"Processing photo job {job_id} for user {user_id} channel={channel}")

    try:
        # Step 1: Build FLUX prompt from all avatar fields
        prompt = build_avatar_prompt(avatar, scene_description)
        logger.debug(f"FLUX prompt ({len(prompt)} chars): {prompt[:120]}...")

        # Step 2: Generate via Replicate FLUX
        generated = await _image_provider.generate(prompt, aspect_ratio="2:3")
        logger.info(f"Replicate image URL: {generated.url[:80]}")

        # Step 3: Download immediately (URL expires ~1h — RESEARCH.md Pitfall 1)
        async with httpx.AsyncClient(timeout=60.0) as client:
            resp = await client.get(generated.url)
            resp.raise_for_status()
            image_bytes = resp.content
        logger.info(f"Downloaded {len(image_bytes)} bytes from Replicate")

        # Step 4: Apply visible watermark (compliance requirement)
        watermarked_bytes = apply_watermark(image_bytes)

        # Step 5: Upload to Supabase Storage private bucket
        storage_path = f"{user_id}/{job_id}.jpg"
        supabase_admin.storage.from_(PHOTO_BUCKET).upload(
            storage_path,
            watermarked_bytes,
            file_options={"content-type": "image/jpeg", "upsert": "true"},
        )
        logger.info(f"Uploaded to Supabase Storage: {storage_path}")

        # Step 6: Generate Supabase signed URL (24h expiry)
        sign_response = (
            supabase_admin.storage
            .from_(PHOTO_BUCKET)
            .create_signed_url(storage_path, SIGNED_URL_EXPIRY)
        )
        signed_url = sign_response.get("signedURL") or sign_response.get("signed_url")
        if not signed_url:
            raise ValueError("Supabase Storage did not return a signed URL")
        logger.info(f"Signed URL generated (24h expiry)")

        # Step 7: Audit log — compliance (image generation tracking per CONTEXT.md)
        try:
            supabase_admin.from_("audit_log").insert({
                "user_id": user_id,
                "event_type": "photo_generated",
                "event_category": "image_generation",
                "action": "generate",
                "resource_type": "photo",
                "event_data": {
                    "prompt": prompt[:500],
                    "model": generated.model,
                    "storage_path": storage_path,
                    "job_id": job_id,
                },
                "result": "success",
            }).execute()
        except Exception as e:
            logger.warning(f"Audit log write failed (non-fatal): {e}")

        # Step 8: Deliver to user via channel
        if channel == "whatsapp":
            await _deliver_whatsapp(user_id, signed_url)
        else:
            await _deliver_web(user_id, avatar, signed_url)

        logger.info(f"Photo job {job_id} completed successfully")

    except Exception as e:
        logger.error(f"Photo job {job_id} failed (attempt {job.attemptsMade + 1}): {e}")

        # Notify user only on last attempt (all retries exhausted)
        max_attempts = job.opts.get("attempts", 3) if job.opts else 3
        if job.attemptsMade >= max_attempts - 1:
            logger.warning(f"All retries exhausted for job {job_id} — sending failure notification")
            try:
                if channel == "whatsapp":
                    await _deliver_whatsapp(user_id, PHOTO_FAILURE_MSG)
                else:
                    supabase_admin.from_("messages").insert({
                        "user_id": user_id,
                        "avatar_id": avatar.get("id") if avatar else None,
                        "channel": "web",
                        "role": "assistant",
                        "content": PHOTO_FAILURE_MSG,
                    }).execute()
            except Exception as notify_err:
                logger.error(f"Failure notification also failed for user {user_id}: {notify_err}")

        raise  # Re-raise so BullMQ records failure and triggers retry
```

Add `bullmq==2.19.5` to `backend/requirements.txt`.
  </action>
  <verify>
    <automated>cd "C:/Users/raphg/Desktop/IA/ava2/backend" && python -c "from app.services.jobs.queue import get_photo_queue, enqueue_photo_job; from app.services.jobs.processor import process_photo_job, _deliver_web, _deliver_whatsapp; print('All jobs package imports OK')"</automated>
    <sampling_rate>run after task 1, before task 2</sampling_rate>
  </verify>
  <done>
    jobs package imports without errors. queue.py has get_photo_queue() and enqueue_photo_job() with attempts=3 exponential backoff. processor.py has full 8-step pipeline with web/WhatsApp delivery split. bullmq==2.19.5 in requirements.txt.
  </done>
</task>

<task type="auto">
  <name>Task 2: BullMQ worker entry point (Docker CMD: python worker_main.py)</name>
  <files>backend/worker_main.py</files>
  <action>
Create `backend/worker_main.py` — standalone process entry point for the Docker worker service. Never imports FastAPI. Reads REDIS_URL from env.

```python
"""
BullMQ Worker entry point.

Run as a separate Docker service:
  CMD: python worker_main.py

This process ONLY runs the BullMQ Worker — it never imports or starts FastAPI.
Concurrency: 3 concurrent image generation jobs (Claude's discretion per CONTEXT.md).

Redis connection: parsed from REDIS_URL env var.
  Default: redis://redis:6379 (Docker Compose service name 'redis')
  Override with REDIS_URL env var for local or cloud Redis.

IMPORTANT (RESEARCH.md Pitfall 5): Use the same connection dict format on both
Queue (enqueue) and Worker (consume) to avoid job serialization mismatch.
"""
import asyncio
import logging
import os
from urllib.parse import urlparse

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s — %(message)s",
)
logger = logging.getLogger("ava.worker")


async def main() -> None:
    # Deferred imports ensure env vars (loaded by app.config) are available
    from bullmq import Worker
    from app.services.jobs.processor import process_photo_job

    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")
    parsed = urlparse(redis_url)
    host = parsed.hostname or "redis"
    port = parsed.port or 6379

    logger.info(f"BullMQ worker starting — Redis {host}:{port} concurrency=3")

    worker = Worker(
        "photo_generation",
        process_photo_job,
        {
            "connection": {"host": host, "port": port},
            "concurrency": 3,
        },
    )

    logger.info("Worker ready — listening for photo_generation jobs...")
    # Block forever — process killed by Docker stop signal
    await asyncio.Future()


if __name__ == "__main__":
    asyncio.run(main())
```
  </action>
  <verify>
    <automated>cd "C:/Users/raphg/Desktop/IA/ava2/backend" && python -c "import ast; src = open('worker_main.py').read(); ast.parse(src); print('worker_main.py syntax OK'); assert 'asyncio.Future' in src; print('blocking call present')"</automated>
    <sampling_rate>run after task 2</sampling_rate>
  </verify>
  <done>
    worker_main.py exists at backend/worker_main.py. Valid Python syntax. Creates BullMQ Worker with concurrency=3. Reads REDIS_URL from env with fallback to redis://redis:6379. Blocks with asyncio.Future(). Never imports FastAPI.
  </done>
</task>

</tasks>

<verification>
- `python -c "from app.services.jobs.queue import enqueue_photo_job; print('OK')"` — no error
- `python -c "from app.services.jobs.processor import process_photo_job; print('OK')"` — no error
- `python -c "import ast; ast.parse(open('worker_main.py').read()); print('syntax OK')"` — passes
- `grep "bullmq" backend/requirements.txt` — found with version pin
- `grep "_deliver_web\|_deliver_whatsapp" backend/app/services/jobs/processor.py` — both delivery paths present
- `grep "apply_watermark\|build_avatar_prompt" backend/app/services/jobs/processor.py` — both wired in pipeline
</verification>

<success_criteria>
1. enqueue_photo_job() adds job to BullMQ with attempts=3, exponential backoff (2s/4s/8s)
2. process_photo_job() implements full pipeline: build prompt → Replicate → download → watermark → Supabase upload → signed URL → audit log → deliver
3. Web delivery: assistant photo message inserted into messages table as [PHOTO]url[/PHOTO]
4. WhatsApp delivery: signed URL link sent via send_whatsapp_message() to user phone
5. All-retries-exhausted: failure notification sent via same channel
6. worker_main.py runs standalone with `python worker_main.py`; concurrency=3; blocks on asyncio.Future()
</success_criteria>

<output>
After completion, create `.planning/phases/07-avatar-system-production/07-03-SUMMARY.md`
</output>
