---
phase: 04-secretary-skills
plan: "05"
type: execute
wave: 3
depends_on: ["04-01", "04-03", "04-04"]
files_modified:
  - backend/app/services/chat.py
  - backend/app/services/skills/__init__.py
  - backend/tests/test_secretary_skills.py
autonomous: true
requirements: [SECR-01, SECR-02, SECR-03, ARCH-01]

must_haves:
  truths:
    - "Secretary mode messages are classified by intent before reaching the LLM fallback"
    - "calendar_add and calendar_view intents are dispatched to CalendarSkill without hitting the LLM"
    - "research intents are dispatched to ResearchSkill without hitting the LLM"
    - "chat intent falls through to the existing LLM call (no regression)"
    - "Intimate mode messages bypass intent classification entirely and go straight to LLM"
    - "Automated tests confirm secretary dispatch works end-to-end with mock skills"
  artifacts:
    - path: "backend/app/services/chat.py"
      provides: "ChatService with skill dispatch integrated into secretary mode path"
      contains: "classify_intent"
    - path: "backend/app/services/skills/__init__.py"
      provides: "Eager skill registration — imports all skill modules to populate registry"
      contains: "from app.services.skills"
    - path: "backend/tests/test_secretary_skills.py"
      provides: "Pytest tests for intent dispatch in secretary mode"
      contains: "async def test_"
  key_links:
    - from: "backend/app/services/chat.py"
      to: "backend/app/services/skills/intent_classifier.py"
      via: "classify_intent() called in secretary mode before LLM fallback"
      pattern: "classify_intent"
    - from: "backend/app/services/chat.py"
      to: "backend/app/services/skills/registry.py"
      via: "registry.get(intent.skill) to dispatch to registered skill handler"
      pattern: "registry\\.get"
    - from: "backend/app/services/skills/__init__.py"
      to: "calendar_skill, research_skill modules"
      via: "import triggers register() calls"
      pattern: "from app.services.skills.calendar_skill"
---

<objective>
Wire the skill dispatch into ChatService so secretary mode routes through intent classification before falling back to the LLM, then add tests confirming the dispatch logic.

Purpose: Plans 01-04 built the skills infrastructure. This plan integrates it into the existing chat pipeline. ChatService.handle_message() must classify intent in secretary mode and dispatch to the correct skill — or fall through to LLM for 'chat' intent. Intimate mode is untouched.

Output: Updated chat.py with skill dispatch, updated skills/__init__.py for eager registration, and test_secretary_skills.py with automated tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-secretary-skills/04-CONTEXT.md
@.planning/phases/04-secretary-skills/04-RESEARCH.md
@.planning/phases/04-secretary-skills/04-01-SUMMARY.md
@.planning/phases/04-secretary-skills/04-04-SUMMARY.md
@backend/app/services/chat.py
@backend/app/services/skills/registry.py
@backend/app/services/skills/intent_classifier.py
@backend/app/services/session/models.py
@backend/tests/test_mode_detection.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update ChatService to dispatch skills in secretary mode and register skills eagerly</name>
  <files>
    backend/app/services/chat.py
    backend/app/services/skills/__init__.py
  </files>
  <action>
**Update backend/app/services/skills/__init__.py:**

Replace the empty package marker with eager skill registration imports. Importing this file (which happens when ChatService imports from skills) must trigger all skill register() calls:

```python
"""Skills package — import all skill modules to register them at startup."""
# These imports trigger register() calls in each skill module.
# To add a new skill: create the module and add an import line here.
from app.services.skills import calendar_skill  # noqa: F401  registers calendar_add, calendar_view
from app.services.skills import research_skill  # noqa: F401  registers research
```

**Update backend/app/services/chat.py:**

Integrate skill dispatch into the SECRETARY mode path ONLY. The integration point is in the "Normal message: call LLM" section, AFTER mode switch detection but BEFORE the LLM call.

Changes to make to chat.py:

1. Add imports at the top (after existing imports):
```python
from openai import AsyncOpenAI
from app.services.skills import registry  # triggers eager skill registration via __init__
from app.services.skills.intent_classifier import classify_intent
```

2. Update `ChatService.__init__` to accept an optional `openai_client` parameter for the intent classifier. The intent classifier needs an AsyncOpenAI client. Since ChatService already has `self._llm` (an LLMProvider), access the underlying client via the OpenAI provider if possible, OR instantiate a separate AsyncOpenAI client for classification using settings:

```python
from app.config import settings as _settings

def __init__(self, llm: LLMProvider, session_store: SessionStore | None = None):
    self._llm = llm
    self._store = session_store or get_session_store()
    # Intent classifier uses a separate AsyncOpenAI client — lightweight gpt-4o-mini call
    self._openai_client = AsyncOpenAI(api_key=_settings.openai_api_key, max_retries=1)
    self._intent_model = _settings.llm_model  # reuse configured model
```

3. In the "Normal message: call LLM" section, BEFORE the existing LLM call, add skill dispatch for SECRETARY mode:

Replace this comment block in chat.py:
```python
# --- Normal message: call LLM ---
current_mode = session.mode
history = list(session.history[current_mode])  # snapshot before append
```

With:
```python
# --- Normal message: skill dispatch (secretary) or LLM (intimate) ---
current_mode = session.mode
history = list(session.history[current_mode])  # snapshot before append

# Secretary mode: classify intent and dispatch to skill if applicable
# Intimate mode: bypass intent classification entirely — go straight to LLM
if current_mode == ConversationMode.SECRETARY:
    try:
        intent = await classify_intent(
            self._openai_client, incoming_text, self._intent_model
        )
        if intent.skill != "chat":
            # Get user's timezone from avatar (default UTC if not set)
            user_tz = avatar.get("timezone", "UTC") if avatar else "UTC"
            skill = registry.get(intent.skill)
            if skill is not None:
                skill_reply = await skill.handle(user_id, intent, user_tz)
                # Append both turns to history so skill responses are part of context
                await self._store.append_message(
                    user_id, current_mode, {"role": "user", "content": incoming_text}
                )
                await self._store.append_message(
                    user_id, current_mode, {"role": "assistant", "content": skill_reply}
                )
                return skill_reply
    except Exception as e:
        logger.error(f"Skill dispatch failed for user {user_id}, falling back to LLM: {e}")
        # Fall through to LLM on any skill dispatch error — never break the chat
```

The existing LLM call block continues unchanged after this insertion.

**Critical constraints:**
- `if current_mode == ConversationMode.SECRETARY:` gate is mandatory — intimate mode must NEVER call intent classifier (per RESEARCH.md Pitfall 6 and CONTEXT.md)
- Skill dispatch errors fall through to LLM silently — never surface to user as errors
- Avatar timezone read from avatar dict; default "UTC" if not present (avatar schema may not have timezone field yet — defensive coding)
  </action>
  <verify>
    <automated>cd /c/Users/raphg/Desktop/IA/ava2/backend && python -c "
from app.services.chat import ChatService
from app.services.skills.registry import list_skills
# Verify skills registered (triggered by chat.py imports)
assert 'calendar_add' in list_skills(), 'calendar_add not registered'
assert 'calendar_view' in list_skills(), 'calendar_view not registered'
assert 'research' in list_skills(), 'research not registered'
print('ChatService + skill registry OK:', list_skills())
"</automated>
    <manual>
      Read chat.py and confirm:
      1. classify_intent is imported
      2. ConversationMode.SECRETARY gate exists before classify_intent call
      3. Intimate mode path is unchanged
      4. Skill dispatch error falls through to LLM (try/except with logger.error)
    </manual>
  </verify>
  <done>
    skills/__init__.py imports calendar_skill and research_skill modules; chat.py integrates classify_intent + registry.get dispatch in secretary mode; intimate mode LLM path is unchanged; all 3 skills registered when ChatService is imported
  </done>
</task>

<task type="auto">
  <name>Task 2: Write automated tests for secretary skill dispatch</name>
  <files>
    backend/tests/test_secretary_skills.py
  </files>
  <action>
Create backend/tests/test_secretary_skills.py with pytest-asyncio tests confirming skill dispatch in ChatService secretary mode.

Tests must use mocks to avoid real OpenAI API calls and real Supabase calls. Follow the existing test patterns in backend/tests/test_mode_detection.py and test_session_store.py.

```python
"""Tests for secretary skill dispatch in ChatService.

Tests confirm:
1. Secretary mode: intent classifier is called; skill handler is dispatched for non-chat intents
2. Intimate mode: intent classifier is NOT called; LLM is called directly
3. Skill dispatch errors fall back to LLM gracefully
4. 'chat' intent falls through to LLM even in secretary mode

Uses unittest.mock.AsyncMock to avoid real API calls.
"""
import pytest
from unittest.mock import AsyncMock, MagicMock, patch
from app.services.chat import ChatService
from app.services.session.models import ConversationMode
from app.services.skills.registry import ParsedIntent


# ---------------------------------------------------------------------------
# Fixtures
# ---------------------------------------------------------------------------

def make_avatar(name: str = "Ava", personality: str = "caring", tz: str = "UTC") -> dict:
    return {"id": "avatar-uuid", "name": name, "personality": personality, "timezone": tz}


@pytest.fixture
def mock_llm():
    llm = MagicMock()
    llm.complete = AsyncMock(return_value="LLM response")
    return llm


@pytest.fixture
def mock_store():
    store = MagicMock()
    session = MagicMock()
    session.mode = ConversationMode.SECRETARY
    session.pending_switch_to = None
    session.history = {
        ConversationMode.SECRETARY: [],
        ConversationMode.INTIMATE: [],
    }
    store.get_or_create = AsyncMock(return_value=session)
    store.append_message = AsyncMock()
    store.switch_mode = AsyncMock()
    return store, session


# ---------------------------------------------------------------------------
# Tests: secretary mode dispatch
# ---------------------------------------------------------------------------

@pytest.mark.asyncio
async def test_secretary_calendar_add_dispatches_to_skill(mock_llm, mock_store):
    """calendar_add intent routes to CalendarSkill, not LLM."""
    store, session = mock_store
    service = ChatService(llm=mock_llm, session_store=store)

    calendar_intent = ParsedIntent(
        skill="calendar_add",
        raw_text="Add team standup Tuesday at 3pm",
        extracted_title="team standup",
        extracted_date="Tuesday at 3pm",
    )

    with patch(
        "app.services.chat.classify_intent", new=AsyncMock(return_value=calendar_intent)
    ):
        mock_skill = MagicMock()
        mock_skill.handle = AsyncMock(return_value="Added: Team standup · Tue · 3:00pm")

        with patch("app.services.chat.registry.get", return_value=mock_skill):
            reply = await service.handle_message(
                user_id="user-123",
                incoming_text="Add team standup Tuesday at 3pm",
                avatar=make_avatar(),
            )

    assert reply == "Added: Team standup · Tue · 3:00pm"
    mock_skill.handle.assert_called_once()
    mock_llm.complete.assert_not_called()  # LLM must NOT be called


@pytest.mark.asyncio
async def test_secretary_research_dispatches_to_skill(mock_llm, mock_store):
    """research intent routes to ResearchSkill, not LLM."""
    store, session = mock_store
    service = ChatService(llm=mock_llm, session_store=store)

    research_intent = ParsedIntent(
        skill="research",
        raw_text="What is quantum entanglement?",
        query="quantum entanglement",
    )

    with patch(
        "app.services.chat.classify_intent", new=AsyncMock(return_value=research_intent)
    ):
        mock_skill = MagicMock()
        mock_skill.handle = AsyncMock(return_value="Quantum entanglement is a phenomenon...\n\nSource: https://example.com")

        with patch("app.services.chat.registry.get", return_value=mock_skill):
            reply = await service.handle_message(
                user_id="user-123",
                incoming_text="What is quantum entanglement?",
                avatar=make_avatar(),
            )

    assert "Quantum entanglement" in reply
    mock_skill.handle.assert_called_once()
    mock_llm.complete.assert_not_called()


@pytest.mark.asyncio
async def test_secretary_chat_intent_falls_through_to_llm(mock_llm, mock_store):
    """'chat' intent bypasses skills and routes to LLM."""
    store, session = mock_store
    service = ChatService(llm=mock_llm, session_store=store)

    chat_intent = ParsedIntent(skill="chat", raw_text="How are you?")

    with patch(
        "app.services.chat.classify_intent", new=AsyncMock(return_value=chat_intent)
    ):
        reply = await service.handle_message(
            user_id="user-123",
            incoming_text="How are you?",
            avatar=make_avatar(),
        )

    assert reply == "LLM response"
    mock_llm.complete.assert_called_once()


@pytest.mark.asyncio
async def test_intimate_mode_bypasses_intent_classifier(mock_llm, mock_store):
    """Intimate mode must NOT call intent classifier — goes straight to LLM."""
    store, session = mock_store
    session.mode = ConversationMode.INTIMATE  # Set to intimate mode
    service = ChatService(llm=mock_llm, session_store=store)

    with patch(
        "app.services.chat.classify_intent", new=AsyncMock()
    ) as mock_classify:
        reply = await service.handle_message(
            user_id="user-123",
            incoming_text="I feel so connected to you",
            avatar=make_avatar(),
        )

    mock_classify.assert_not_called()  # CRITICAL: classifier must not run in intimate mode
    assert reply == "LLM response"


@pytest.mark.asyncio
async def test_skill_dispatch_error_falls_back_to_llm(mock_llm, mock_store):
    """Skill dispatch failure (e.g., network error) falls back to LLM — never crashes."""
    store, session = mock_store
    service = ChatService(llm=mock_llm, session_store=store)

    failing_intent = ParsedIntent(skill="research", raw_text="What is dark matter?", query="dark matter")

    with patch(
        "app.services.chat.classify_intent", new=AsyncMock(return_value=failing_intent)
    ):
        mock_skill = MagicMock()
        mock_skill.handle = AsyncMock(side_effect=Exception("Tavily API down"))

        with patch("app.services.chat.registry.get", return_value=mock_skill):
            reply = await service.handle_message(
                user_id="user-123",
                incoming_text="What is dark matter?",
                avatar=make_avatar(),
            )

    # Falls back to LLM, not an error message
    assert reply == "LLM response"
    mock_llm.complete.assert_called_once()
```
  </action>
  <verify>
    <automated>cd /c/Users/raphg/Desktop/IA/ava2/backend && python -m pytest tests/test_secretary_skills.py -v</automated>
    <manual>
      Confirm all 5 tests pass:
      - test_secretary_calendar_add_dispatches_to_skill
      - test_secretary_research_dispatches_to_skill
      - test_secretary_chat_intent_falls_through_to_llm
      - test_intimate_mode_bypasses_intent_classifier
      - test_skill_dispatch_error_falls_back_to_llm
    </manual>
  </verify>
  <done>
    All 5 new tests pass; all Phase 3 tests still pass; intimate mode guard confirmed by test; skill error fallback to LLM confirmed by test
  </done>
</task>

</tasks>

<verification>
Run full test suite to confirm no regressions:
```bash
cd /c/Users/raphg/Desktop/IA/ava2/backend && python -m pytest tests/ -v
```
Expected: all Phase 3 tests pass, all 5 new secretary skill dispatch tests pass.

Confirm skill registry is populated when ChatService is imported:
```bash
cd /c/Users/raphg/Desktop/IA/ava2/backend && python -c "
from app.services.chat import ChatService
from app.services.skills.registry import list_skills
skills = list_skills()
assert 'calendar_add' in skills
assert 'calendar_view' in skills
assert 'research' in skills
print('All skills registered:', skills)
"
```
</verification>

<success_criteria>
- chat.py integrates classify_intent + registry.get dispatch gated behind ConversationMode.SECRETARY check
- Intimate mode path is entirely unchanged — no classify_intent call possible in intimate mode
- skills/__init__.py imports calendar_skill and research_skill modules (eager registration)
- test_secretary_skills.py has 5 tests all passing: calendar dispatch, research dispatch, chat fallthrough, intimate bypass, error fallback
- Full test suite passes: pytest tests/ with 0 failures
- New modular architecture: adding a new skill requires only (a) creating skill module with register() and (b) adding import to skills/__init__.py — no routing logic changes
</success_criteria>

<output>
After completion, create `.planning/phases/04-secretary-skills/04-05-SUMMARY.md`
</output>
